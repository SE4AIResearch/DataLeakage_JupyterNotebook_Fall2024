{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nb_303674\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# \n",
    "# ### A Classic Naive Bayes Example (80% of Doctors get this wrong):\n",
    "# 1% of women at age forty who participate in routine screening have breast cancer.  80% of women with breast cancer will get positive mammographies.  9.6% of women without breast cancer will also get positive mammographies.  A woman in this age group had a positive mammography in a routine screening.  \n",
    "# \n",
    "# What is the probability that she actually has breast cancer?\n",
    "# \n",
    "# > .0776\n",
    "# \n",
    "# <!--\n",
    "# * Prior: 1% of women at age forty have breast cancer.\n",
    "# * Posterior: Probability woman has breast cancer\n",
    "# -->\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    ".8 * .01 / (.8 * .01 + .096 * .99)\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "critics = pd.read_csv('../../DAT18NYC/data/rt_critics.csv')\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
    "\n",
    "get_ipython().run_line_magic('pinfo', 'CountVectorizer')\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2))\n",
    "\n",
    "vectorizer.fit(text)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "x = vectorizer.transform(text)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "print('Sparse Matrix')\n",
    "print(x)\n",
    "print(type(x))\n",
    "print()\n",
    "print('Matrix')\n",
    "x_back = x.toarray()\n",
    "print(x_back)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "pd.DataFrame(x_back, columns = vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "print(critics.quote[2])\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "rotten_vectorizer = vectorizer.fit(critics.quote)\n",
    "x = vectorizer.fit_transform(critics.quote)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "critics.head()\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "y = (critics.fresh == 'fresh').values.astype(int)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def train_and_measure(classifier, x, y, test_size):\n",
    "    from sklearn import model_selection\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x, y, test_size = 0.2, random_state = 1234)\n",
    "    clf = classifier.fit(xtrain, ytrain)\n",
    "    \n",
    "    training_accuracy = clf.score(xtrain, ytrain)\n",
    "    test_accuracy = clf.score(xtest, ytest)\n",
    "    \n",
    "    print(classifier)\n",
    "    print(\"Accuracy on training data: %0.2f\" % training_accuracy)\n",
    "    print(\"Accuracy on test data: %0.2f\" % test_accuracy)\n",
    "    \n",
    "train_and_measure(naive_bayes.MultinomialNB(), x, y, .2)\n",
    "\n",
    "x_ones = (x > 1) # recall that a bernoulli interpretation will only work with 1s and 0s, or binary data.\n",
    "train_and_measure(naive_bayes.BernoulliNB(), x_ones, y, .2)\n",
    "    \n",
    "from sklearn import linear_model\n",
    "train_and_measure(linear_model.LogisticRegression(), x, y, .2)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def kfold_average_sd (classifier, n, x, y, return_plot = False):\n",
    "    import numpy as np\n",
    "    from sklearn import model_selection\n",
    "    kfold = model_selection.KFold(n_splits = n, random_state=1234, shuffle=True)\n",
    "    \n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for train_index, test_index in kfold:\n",
    "        clf = classifier.fit(x[train_index], y[train_index])\n",
    "        train_acc.append(clf.score(x[train_index], y[train_index]))\n",
    "        test_acc.append(clf.score(x[test_index], y[test_index]))\n",
    "\n",
    "    if return_plot:\n",
    "        plt.figure()\n",
    "        sns.kdeplot(np.random.normal(loc=np.array(test_acc).mean(), scale=np.array(test_acc).std(), size=10000), shade=True)\n",
    "\n",
    "    \n",
    "    return np.array(test_acc).mean(), np.array(test_acc).std()\n",
    "\n",
    "kfold_average_sd(naive_bayes.MultinomialNB(), 5, x, y, True)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "def find_k(classifier, x, y, max_num_k):\n",
    "    from sklearn import cross_validation\n",
    "    import numpy as np\n",
    "\n",
    "    k_train_acc = []\n",
    "    k_test_acc = []\n",
    "    for i in range(2, max_num_k):\n",
    "        kfold = model_selection.KFold(n_splits=i, shuffle=True, random_state=1234)\n",
    "        test_acc, train_acc = [], []\n",
    "        for train_index, test_index in kfold:\n",
    "            clf = classifier.fit(x[train_index], y[train_index])\n",
    "            train_acc.append(clf.score(x[train_index], y[train_index]))\n",
    "            test_acc.append(clf.score(x[test_index], y[test_index]))\n",
    "        k_train_acc.append(np.array(train_acc).mean())\n",
    "        k_test_acc.append(np.array(test_acc).mean())\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(list(range(2, max_num_k)), k_train_acc)\n",
    "    plt.plot(list(range(2, max_num_k)), k_test_acc)\n",
    "    return clf\n",
    "\n",
    "clf = find_k(naive_bayes.MultinomialNB(), x_ones, y, 20)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y_true = y\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "'''\n",
    "Note! the confusion matrix here will be [0 1],\n",
    "not [1, 0] as in the above image.\n",
    "'''\n",
    "conf = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(conf)\n",
    "\n",
    "print(clf.score(x, y))\n",
    "print(conf[0, 0] / (conf[0, 0] + conf[0, 1]))\n",
    "print(conf[1, 1] / (conf[1, 0] + conf[1, 1]))\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "prob = clf.predict_proba(x)[:,0]\n",
    "bad_rotten = np.argsort(prob[y ==0])[:5]\n",
    "bad_fresh = np.argsort(prob[y ==1])[-5:]\n",
    "\n",
    "print(\"Mis-predicted Rotten quotes\")\n",
    "print('---------------------------')\n",
    "for row in bad_rotten:\n",
    "    print(critics[y == 0].quote.iloc[row])\n",
    "    print()\n",
    "\n",
    "print(\"Mis-predicted Fresh quotes\")\n",
    "print('--------------------------')\n",
    "for row in bad_fresh:\n",
    "    print(critics[y == 1].quote.iloc[row])\n",
    "    print()\n",
    "\n",
    "\n",
    "# f_classif method:\n",
    "# -----------------\n",
    "# \n",
    "# As noted in the class notes, we haven't dropped a single feature from our dataset in performing this anaylsis. That is to say, we are using the full set of words used in all the reviews to run our model (some 163505!). Intuitively, we could get a model that performs just as well using a much smaller subest of these features. This is desirable because it makes our model much more efficient to run, without any significant loss of accuracy.\n",
    "# \n",
    "# The class notes suggest investigating the 'f_classif' method from sklearn:\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "get_ipython().run_line_magic('pinfo', 'f_classif')\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "print((f_classif(x,y)))\n",
    "print(len(f_classif(x,y)))\n",
    "print(len(f_classif(x,y)[0]))\n",
    "print(len(f_classif(x,y)[1]))\n",
    "\n",
    "\n",
    "# The documentation tells us that f_classif returns arrays of the Anova F-values and p-values for each feature. A high F-value means a high degree of the variance in the test variable can be explained by variance in the feature. Therefore we should be able to create a good model by only selecting features with high F-values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# \n",
    "# ### A Classic Naive Bayes Example (80% of Doctors get this wrong):\n",
    "# 1% of women at age forty who participate in routine screening have breast cancer.  80% of women with breast cancer will get positive mammographies.  9.6% of women without breast cancer will also get positive mammographies.  A woman in this age group had a positive mammography in a routine screening.  \n",
    "# \n",
    "# What is the probability that she actually has breast cancer?\n",
    "# \n",
    "# > .0776\n",
    "# \n",
    "# <!--\n",
    "# * Prior: 1% of women at age forty have breast cancer.\n",
    "# * Posterior: Probability woman has breast cancer\n",
    "# -->\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    ".8 * .01 / (.8 * .01 + .096 * .99)\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "critics = pd.read_csv('../../DAT18NYC/data/rt_critics.csv')\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['Math is great', 'Math is really great', 'Exciting exciting Math']\n",
    "\n",
    "get_ipython().run_line_magic('pinfo', 'CountVectorizer')\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2))\n",
    "\n",
    "vectorizer.fit(text)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "x = vectorizer.transform(text)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "print('Sparse Matrix')\n",
    "print(x)\n",
    "print(type(x))\n",
    "print()\n",
    "print('Matrix')\n",
    "x_back = x.toarray()\n",
    "print(x_back)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "pd.DataFrame(x_back, columns = vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "print(critics.quote[2])\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "rotten_vectorizer = vectorizer.fit(critics.quote)\n",
    "x = vectorizer.fit_transform(critics.quote)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "critics.head()\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "y = (critics.fresh == 'fresh').values.astype(int)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def train_and_measure(classifier, x, y, test_size):\n",
    "    from sklearn import model_selection\n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x, y, test_size = 0.2, random_state = 1234)\n",
    "    clf = classifier.fit(xtrain, ytrain)\n",
    "    \n",
    "    training_accuracy = clf.score(xtrain, ytrain)\n",
    "    test_accuracy = clf.score(xtest, ytest)\n",
    "    \n",
    "    print(classifier)\n",
    "    print(\"Accuracy on training data: %0.2f\" % training_accuracy)\n",
    "    print(\"Accuracy on test data: %0.2f\" % test_accuracy)\n",
    "    \n",
    "train_and_measure(naive_bayes.MultinomialNB(), x, y, .2)\n",
    "\n",
    "x_ones = (x > 1) # recall that a bernoulli interpretation will only work with 1s and 0s, or binary data.\n",
    "train_and_measure(naive_bayes.BernoulliNB(), x_ones, y, .2)\n",
    "    \n",
    "from sklearn import linear_model\n",
    "train_and_measure(linear_model.LogisticRegression(), x, y, .2)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def kfold_average_sd (classifier, n, x, y, return_plot = False):\n",
    "    import numpy as np\n",
    "    from sklearn import model_selection\n",
    "    kfold = model_selection.KFold(n_splits = n, random_state=1234, shuffle=True)\n",
    "    \n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for train_index, test_index in kfold:\n",
    "        clf = classifier.fit(x[train_index], y[train_index])\n",
    "        train_acc.append(clf.score(x[train_index], y[train_index]))\n",
    "        test_acc.append(clf.score(x[test_index], y[test_index]))\n",
    "\n",
    "    if return_plot:\n",
    "        plt.figure()\n",
    "        sns.kdeplot(np.random.normal(loc=np.array(test_acc).mean(), scale=np.array(test_acc).std(), size=10000), shade=True)\n",
    "\n",
    "    \n",
    "    return np.array(test_acc).mean(), np.array(test_acc).std()\n",
    "\n",
    "kfold_average_sd(naive_bayes.MultinomialNB(), 5, x, y, True)\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "def find_k(classifier, x, y, max_num_k):\n",
    "    from sklearn import cross_validation\n",
    "    import numpy as np\n",
    "\n",
    "    k_train_acc = []\n",
    "    k_test_acc = []\n",
    "    for i in range(2, max_num_k):\n",
    "        kfold = model_selection.KFold(n_splits=i, shuffle=True, random_state=1234)\n",
    "        test_acc, train_acc = [], []\n",
    "        for train_index, test_index in kfold:\n",
    "            clf = classifier.fit(x[train_index], y[train_index])\n",
    "            train_acc.append(clf.score(x[train_index], y[train_index]))\n",
    "            test_acc.append(clf.score(x[test_index], y[test_index]))\n",
    "        k_train_acc.append(np.array(train_acc).mean())\n",
    "        k_test_acc.append(np.array(test_acc).mean())\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(list(range(2, max_num_k)), k_train_acc)\n",
    "    plt.plot(list(range(2, max_num_k)), k_test_acc)\n",
    "    return clf\n",
    "\n",
    "clf = find_k(naive_bayes.MultinomialNB(), x_ones, y, 20)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y_true = y\n",
    "y_pred = clf.predict(x)\n",
    "\n",
    "'''\n",
    "Note! the confusion matrix here will be [0 1],\n",
    "not [1, 0] as in the above image.\n",
    "'''\n",
    "conf = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(conf)\n",
    "\n",
    "print(clf.score(x, y))\n",
    "print(conf[0, 0] / (conf[0, 0] + conf[0, 1]))\n",
    "print(conf[1, 1] / (conf[1, 0] + conf[1, 1]))\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "prob = clf.predict_proba(x)[:,0]\n",
    "bad_rotten = np.argsort(prob[y ==0])[:5]\n",
    "bad_fresh = np.argsort(prob[y ==1])[-5:]\n",
    "\n",
    "print(\"Mis-predicted Rotten quotes\")\n",
    "print('---------------------------')\n",
    "for row in bad_rotten:\n",
    "    print(critics[y == 0].quote.iloc[row])\n",
    "    print()\n",
    "\n",
    "print(\"Mis-predicted Fresh quotes\")\n",
    "print('--------------------------')\n",
    "for row in bad_fresh:\n",
    "    print(critics[y == 1].quote.iloc[row])\n",
    "    print()\n",
    "\n",
    "\n",
    "# f_classif method:\n",
    "# -----------------\n",
    "# \n",
    "# As noted in the class notes, we haven't dropped a single feature from our dataset in performing this anaylsis. That is to say, we are using the full set of words used in all the reviews to run our model (some 163505!). Intuitively, we could get a model that performs just as well using a much smaller subest of these features. This is desirable because it makes our model much more efficient to run, without any significant loss of accuracy.\n",
    "# \n",
    "# The class notes suggest investigating the 'f_classif' method from sklearn:\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "get_ipython().run_line_magic('pinfo', 'f_classif')\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "print((f_classif(x,y)))\n",
    "print(len(f_classif(x,y)))\n",
    "print(len(f_classif(x,y)[0]))\n",
    "print(len(f_classif(x,y)[1]))\n",
    "\n",
    "\n",
    "# The documentation tells us that f_classif returns arrays of the Anova F-values and p-values for each feature. A high F-value means a high degree of the variance in the test variable can be explained by variance in the feature. Therefore we should be able to create a good model by only selecting features with high F-values. \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
