{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from random import randrange, choice\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from unbalanced_dataset import SMOTE\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "r = pd.read_csv('/Users/Felipe/PycharmProjects/FracasoEscolarChile/DatasetsProcesados/SIMCE/ALU/SIMCE_GEO_2013-2014.csv', sep='|', decimal='.')\n",
    "r2 = pd.read_csv('/Users/Felipe/PycharmProjects/FracasoEscolarChile/DatasetsProcesados/RBD_GEO_2013_MUESTRA.csv', sep=',', decimal='.')\n",
    "r = r.drop(r.columns[0:3],1)\n",
    "#r = r[r.SIT_FIN_R != \"Y\"]\n",
    "r = r[(r.GSE_MANZANA_ALU > 0) & (r.CPAD_DISP == 1)]\n",
    "c = pd.merge(r,r2, how=\"inner\", on=['RBD'])\n",
    "r.SIT_FIN_R = preprocessing.LabelEncoder().fit_transform(r.SIT_FIN_R)\n",
    "r.LET_CUR = preprocessing.LabelEncoder().fit_transform(r.LET_CUR)\n",
    "r.GSE_MANZANA_ALU = preprocessing.LabelEncoder().fit_transform(r.GSE_MANZANA_ALU)\n",
    "c['IVE_POND'] = c[['IVE_BASICA_RBD','IVE_MEDIA_RBD']].apply(lambda x:x.mean(),axis=1)\n",
    "c['CONVIVENCIA_POND'] = c.filter(regex=\"CONVIVENCIA\").apply(lambda x:x.mean(),axis=1)\n",
    "c['AUTOESTIMA_MOTIVACION_POND'] = c.filter(regex=\"AUTOESTIMA_MOTIVACION\").apply(lambda x:x.mean(),axis=1)\n",
    "c['PARTICIPACION_POND'] = c.filter(regex=\"PARTICIPACION\").apply(lambda x:x.mean(),axis=1)\n",
    "r = c[['COD_ENSE','COD_GRADO','COD_JOR','GEN_ALU','COD_COM_ALU','REPITENTE_ALU','ABANDONA_ALU','SOBRE_EDAD_ALU','CANT_TRASLADOS_ALU','DIST_ALU_A_RBD_C','DIST_ALU_A_RBD','DESERTA_ALU','EDU_M','EDU_P','ING_HOGAR','TASA_ABANDONO_RBD','TASA_REPITENCIA_RBD','TASA_TRASLADOS_RBD','IAV_MANZANA_RBD','CULT_MANZANA_RBD','DISP_GSE_MANZANA_RBD','DEL_DROG_MANZANA_RBD','CANT_CURSOS_RBD','CANT_DELITOS_MANZANA_RBD','PROF_AULA_H_MAT_RBD','PROF_TAXI_H_MAT_RBD','CONVIVENCIA_POND','AUTOESTIMA_MOTIVACION_POND','PARTICIPACION_POND','PORC_HORAS_LECTIVAS_DOC_RBD','PROM_EDAD_TITULACION_DOC_RBD','PROM_EDAD_DOC_RBD','PROM_ANOS_SERVICIO_DOC_RBD','PROM_ANOS_ESTUDIOS_DOC_RBD','CANT_DOC_RBD','PAGO_MATRICULA_RBD','PAGO_MENSUAL_RBD','IVE_POND']]\n",
    "r = r.dropna()\n",
    "def f(x):\n",
    "    if x.name != \"ABANDONA_ALU\":\n",
    "        min_max_scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "        return min_max_scaler.fit_transform(x)\n",
    "    return x\n",
    "r = r.apply(f, axis=0)\n",
    "X = np.array(r.drop(['DESERTA_ALU','ABANDONA_ALU'],1))\n",
    "y = np.array(r['ABANDONA_ALU'])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.33)\n",
    "estimator_log = SGDClassifier(loss=\"log\", penalty=\"l2\", n_jobs=-1,  class_weight='auto')\n",
    "estimator_linear = SGDClassifier(loss=\"hinge\", penalty=\"l2\", n_jobs=-1,  class_weight='auto')\n",
    "estimator_per = SGDClassifier(loss=\"perceptron\", penalty=\"l2\", n_jobs=-1,  class_weight='auto')\n",
    "estimator_mh = SGDClassifier(loss=\"modified_huber\", penalty=\"l2\", n_jobs=-1,  class_weight='auto')\n",
    "estimator_h = SGDClassifier(loss=\"squared_hinge\", penalty=\"l2\", n_jobs=-1,  class_weight='auto')\n",
    "estimator_hu = SGDClassifier(loss=\"huber\", penalty=\"l2\", n_jobs=-1,  class_weight='auto')\n",
    "for estimator in [estimator_log, estimator_linear,estimator_h,estimator_hu,estimator_mh,estimator_per]:\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    m = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\n\")\n",
    "    print((\"Modelo : \" + estimator.loss))\n",
    "    print(\"Matriz de Confusion : \")\n",
    "    print(m)\n",
    "    print(\"Precision Total de %f, un %f en la retencion(Clase 0) y %f en la desercion(Clase 1).\" % ((m[0][0]+m[1][1])/(m[0][0]+m[0][1]+m[1][1]+m[1][0]),m[0][0]/(m[0][0]+m[0][1]),m[1][1]/(m[1][1]+m[1][0]))*1)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "m = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Modelo : Naive-Bayes\")\n",
    "print(\"Matriz de Confusion : \")\n",
    "print(m)\n",
    "print(\"Precision Total de %f, un %f en la retencion(Clase 0) y %f en la desercion(Clase 1).\" % ((m[0][0]+m[1][1])/(m[0][0]+m[0][1]+m[1][1]+m[1][0]),m[0][0]/(m[0][0]+m[0][1]),m[1][1]/(m[1][1]+m[1][0]))*1)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "X.shape\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "y.shape\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
